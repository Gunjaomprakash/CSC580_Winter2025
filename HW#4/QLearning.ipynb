{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081b2554",
   "metadata": {},
   "source": [
    "# CSC 580 HW#4 \"QLearning.ipynb\" -- Q-learning for the Snake Game\n",
    "# ** Initial Code **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237f6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: import-ipynb in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (0.1.4)\n",
      "Requirement already satisfied: IPython in c:\\programdata\\anaconda3\\lib\\site-packages (from import-ipynb) (8.2.0)\n",
      "Requirement already satisfied: nbformat in c:\\programdata\\anaconda3\\lib\\site-packages (from import-ipynb) (5.3.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (2.11.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (61.2.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.18.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.1.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (3.0.20)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: fastjsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (2.15.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (4.9.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->import-ipynb) (302)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from asttokens->stack-data->IPython->import-ipynb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# First install this library so that we can import code from other Notebooks\n",
    "## https://newbedev.com/how-to-import-functions-of-a-jupyter-notebook-into-another-jupyter-notebook-in-google-colab#:~:text=How%20to%20import%20functions%20of%20a%20jupyter%20notebook,mount%20your%20google%20drive%20to%20access%20your%20xxx.ipynb\n",
    "!pip install import-ipynb\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e45d56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SnakeEnv.ipynb\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: shimmy<1.0,>=0.1.0 in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\users\\ntomuro\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.7.0)\n",
      "importing Jupyter notebook from Agent.ipynb\n"
     ]
    }
   ],
   "source": [
    "import SnakeEnv as snake_env\n",
    "import Agent as agent_class\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f778a8",
   "metadata": {},
   "source": [
    "## Q-Learning -- Off-policy Temporal Difference Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee44e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(agent, env, max_steps, train=True):\n",
    "    \"\"\"\n",
    "    This function simulates a RL game, where the agent learns the (hopefully) optimal policy\n",
    "    by Q-learning.  The parameters 'agent' and 'env' are created in the calling function and\n",
    "    passed in, while 'max_step' specifies the maximum timesteps to play (Note: continuous \n",
    "    after failing) and 'train' indicates the run is a training or otherwise (i.e., evaluation).\n",
    "    Most lines are basic and general, calling functions in the environment or the agent.  \n",
    "    Details depend on the implementations of those components (and their functions).\n",
    "    \"\"\"\n",
    "    # First reset the environment\n",
    "    state = env.reset()\n",
    "    agent.init_state(state) #(A)\n",
    "    \n",
    "    # Initialize some housekeeping variables\n",
    "    total_return, n_apples, n_stops, n_goodsteps = 0.0, 0, 0, 0\n",
    "    done = False\n",
    "   \n",
    "    # Play continuously until max_steps.\n",
    "    for i in range(max_steps):\n",
    "        \n",
    "        # Select the action to take at this state. \n",
    "        if train:\n",
    "            action = agent.select_action(state)  #(A) epsilon greedy selection\n",
    "        else:\n",
    "            action = agent.select_greedy(state)  #(A) greedy selection\n",
    "        \n",
    "        # Environment executes the selected action.\n",
    "        next_state, reward, done, _ = env.step(action) \n",
    "        \n",
    "        # Q-learning if training -- update the Q-table\n",
    "        if train:\n",
    "            agent.update_Qtable(state, action, reward, next_state)  #(A) \n",
    "            \n",
    "        # Update to prepare for the next iteration\n",
    "        state = next_state\n",
    "        \n",
    "        # Accumulate the total return and other counts from this step\n",
    "        total_return += pow(agent.gamma, i) * reward\n",
    "\n",
    "        if reward == 10:\n",
    "            n_apples += 1\n",
    "        elif reward == 1:\n",
    "            n_goodsteps += 1\n",
    "        # The play is continuous, so this condition doesn't make the play terminate,\n",
    "        # but an episode stops when a snake curls itself or hits a wall.\n",
    "        elif reward == -100:  # i.e., done\n",
    "            n_stops += 1\n",
    "        #\n",
    "    return total_return, n_apples, n_stops, n_goodsteps, agent.num_states_visited() #(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a64d6",
   "metadata": {},
   "source": [
    "# TD Training/Learning -- If you are ** evaluating ** the learned policy, do NOT click this cell; instead click the next cell (TD evaluation).\n",
    "## The cell below *learns* the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd7e20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Run 0: Return= -20.146, #Apples=2, #Stops=38, #GoodSteps=477, #StatesVisited=0\n",
      "\n",
      "** Mean: Return= -20.146, #Apples=2.0, #Stops=38.0, #GoodSteps=477.0, #StatesVisited=0.0\n"
     ]
    }
   ],
   "source": [
    "# Do/call q_learning for 'num_runs' times.  For each run, 'num_steps' steps is done.\n",
    "# Note that agent and environment are created anew and parameters are (re-)initialized \n",
    "# for every run.\n",
    "#\n",
    "# NOTE: Set env.display to True or False to control the graphic visualization. \n",
    "# But note that after visualizing once, the whole code has to be re-started (i.e., \n",
    "# restart kernel) due to the bug(s) in the turtle library.\n",
    "\n",
    "num_runs = 1\n",
    "num_steps = 1000\n",
    "results_list = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    params = dict()\n",
    "    params['gamma'] = 0.95\n",
    "    params['alpha'] = 0.7\n",
    "    params['epsilon'] = 0.6         # exploration probability at start\n",
    "    params['epsilon_min'] = .01     # minimum epsilon\n",
    "    params['epsilon_decay'] = .995  # exponential decay rate for epsilon\n",
    "\n",
    "    # Create an environment and an agent\n",
    "    env = snake_env.SnakeEnv()\n",
    "    agent = agent_class.Agent(env, params)\n",
    "\n",
    "    env.display = False #True      ## (**) display on/off\n",
    "\n",
    "    ret = q_learning(agent, env, num_steps, True) # training=True\n",
    "    results_list.append(ret)\n",
    "\n",
    "    env.close()\n",
    "    print (\"* Run {}: Return={:>8.3f}, #Apples={}, #Stops={}, #GoodSteps={}, #StatesVisited={}\"\n",
    "           .format(run, ret[0], ret[1], ret[2], ret[3], ret[4]))\n",
    "    \n",
    "# Display the mean\n",
    "results = np.array(results_list)\n",
    "cmean = np.mean(results, axis=0)\n",
    "print (\"\\n** Mean: Return={:>8.3f}, #Apples={}, #Stops={}, #GoodSteps={}, #StatesVisited={}\"\n",
    "           .format(cmean[0], cmean[1], cmean[2], cmean[3], cmean[4]))\n",
    "\n",
    "agent.write_qtable(\"qtable.csv\") #(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4e13d",
   "metadata": {},
   "source": [
    "# TD Evaluation -- you run this cell ** after ** you finished coding the training/learning cell above.\n",
    "## Code to *evaluate* the learned policy.  The q-table is read in from the saved csv file.  No learning takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77899c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do q_learning for 'num_runs' times.  For each run, 'num_steps' steps is done.\n",
    "\n",
    "num_runs = 1\n",
    "num_steps = 300\n",
    "results_list = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    params = dict()\n",
    "    params['gamma'] = 0.95\n",
    "    params['alpha'] = 0.7\n",
    "    params['epsilon'] = 0.8         # exploration probability at start\n",
    "    params['epsilon_min'] = .01     # minimum epsilon\n",
    "    params['epsilon_decay'] = .995  # exponential decay rate for epsilon\n",
    "\n",
    "    # Create an environment and an agent\n",
    "    env = snake_env.SnakeEnv()\n",
    "    agent = agent_class.Agent(env, params)\n",
    "    \n",
    "    # Read in the q-table\n",
    "    agent.read_qtable(\"qtable.csv\")\n",
    "\n",
    "    env.display = True      ## <== display on/off\n",
    "\n",
    "    ret = q_learning(agent, env, num_steps, False) # training=False for evaluation\n",
    "    results_list.append(ret)\n",
    "\n",
    "    env.close()\n",
    "    print (\"* Run {}: Return={:>8.3f}, #Apples={}, #Stops={}, #GoodSteps={}, #StatesVisited={}\"\n",
    "           .format(run, ret[0], ret[1], ret[2], ret[3], ret[4]))\n",
    "    \n",
    "# Display the mean\n",
    "results = np.array(results_list)\n",
    "cmean = np.mean(results, axis=0)\n",
    "print (\"\\n** Mean: Return={:>8.3f}, #Apples={}, #Stops={}, #GoodSteps={}, #StatesVisited={}\"\n",
    "           .format(cmean[0], cmean[1], cmean[2], cmean[3], cmean[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
